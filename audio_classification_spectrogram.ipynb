{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-process\n",
    "\n",
    "The drumkit sound dataset used for the training is available here:\n",
    "https://drive.google.com/file/d/1_yXHmvD7nLrRfbItgmhTledlksneF028/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drumkit_dataset/0_kick', 'drumkit_dataset/1_snare', 'drumkit_dataset/2_hihat_closed', 'drumkit_dataset/3_hihat_open', 'drumkit_dataset/4_tom_low', 'drumkit_dataset/5_tom_mid', 'drumkit_dataset/6_tom_high', 'drumkit_dataset/7_clap', 'drumkit_dataset/8_rim']\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 256 \n",
    "SR = 16000\n",
    "MELSPEC_SIZE = 128;\n",
    "\n",
    "len_src = 3. \n",
    "ref_n_src = int(SR * len_src)\n",
    "\n",
    "drum_dirs = [r.split('/')[-1].replace('\\\\', '/') for r in sorted(glob('./drumkit_dataset/*'))]\n",
    "NB_CLASS = len(drum_dirs)\n",
    "\n",
    "print (drum_dirs)\n",
    "\n",
    "def get_melspec(filepath, hop_length=HOP_LENGTH, n_mels=128):\n",
    "    y_tmp = np.zeros(ref_n_src)\n",
    "    \n",
    "    y, sr = librosa.core.load(filepath, sr=SR, mono=True)\n",
    "    y = y[:ref_n_src]\n",
    "    y_tmp[:len(y)] = y[:ref_n_src]\n",
    "        \n",
    "    # sfft -> mel conversion\n",
    "    melspec = librosa.feature.melspectrogram(y=y_tmp, sr=sr,\n",
    "                n_fft=N_FFT, hop_length=hop_length, n_mels=n_mels)\n",
    "    S = librosa.power_to_db(melspec)  # Corrected line: removed np.max\n",
    "        \n",
    "    return S\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drum directories: ['0_kick', '1_snare', '2_hihat_closed', '3_hihat_open', '4_tom_low', '5_tom_mid', '6_tom_high', '7_clap', '8_rim']\n",
      "Total files found: 2575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2575 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2575/2575 [00:14<00:00, 178.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 256 \n",
    "SR = 16000\n",
    "MELSPEC_SIZE = 128\n",
    "len_src = 3  \n",
    "ref_n_src = int(SR * len_src)\n",
    "\n",
    "# Function to get Mel Spectrogram\n",
    "def get_melspec(filepath, hop_length=HOP_LENGTH, n_mels=128):\n",
    "    y_tmp = np.zeros(ref_n_src)\n",
    "    y, sr = librosa.load(filepath, sr=SR, mono=True)\n",
    "    y = y[:ref_n_src]\n",
    "    y_tmp[:len(y)] = y[:ref_n_src]\n",
    "    \n",
    "    # SFFT -> Mel conversion\n",
    "    melspec = librosa.feature.melspectrogram(y=y_tmp, sr=sr,\n",
    "                                              n_fft=N_FFT, hop_length=hop_length, n_mels=n_mels)\n",
    "    S = librosa.power_to_db(melspec)  # Corrected to use only one argument\n",
    "    return S\n",
    "\n",
    "# Get drum directories\n",
    "drum_dirs = [os.path.basename(r) for r in sorted(glob('./drumkit_dataset/*'))]\n",
    "print(\"Drum directories:\", drum_dirs)\n",
    "\n",
    "# Get file paths\n",
    "filepaths = glob(\"./drumkit_dataset/*/*\")\n",
    "print(f\"Total files found: {len(filepaths)}\")\n",
    "\n",
    "shuffle(filepaths)\n",
    "\n",
    "drum_genres = []\n",
    "drum_melspecs = []\n",
    "NB_CLASS = len(drum_dirs)\n",
    "\n",
    "# Process files\n",
    "for filepath in tqdm(filepaths):\n",
    "    dir_ = os.path.basename(os.path.dirname(filepath))\n",
    "    \n",
    "    try:\n",
    "        genre = drum_dirs.index(dir_)  # Get genre index\n",
    "        melspec = get_melspec(filepath, HOP_LENGTH, MELSPEC_SIZE)\n",
    "\n",
    "        if melspec.shape[1] > MELSPEC_SIZE:\n",
    "            melspec = melspec[:, :MELSPEC_SIZE]\n",
    "        else:\n",
    "            melspec.resize((MELSPEC_SIZE, MELSPEC_SIZE)) \n",
    "\n",
    "        drum_genres.append(genre)\n",
    "        drum_melspecs.append(melspec)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {filepath} | Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2575,)\n",
      "(2575, 9)\n",
      "(2575, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "drum_genres = np.array(drum_genres)\n",
    "print(drum_genres.shape)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "drum_genres = to_categorical(drum_genres, NB_CLASS)\n",
    "print(drum_genres.shape)\n",
    "\n",
    "drum_melspecs = np.array(drum_melspecs)\n",
    "drum_melspecs = np.expand_dims(drum_melspecs, 3)\n",
    "print(drum_melspecs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"drum_data_128.npz\", melspecs=drum_melspecs, genres=drum_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading from pre-processed npz file\n",
    "# drum_melspecs = np.load(\"drum_data_128.npz\")['melspecs']\n",
    "# drum_genres = np.load(\"drum_data_128.npz\")['genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import BatchNormalization,Activation\n",
    "from keras.layers import ELU\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "SIZE = MELSPEC_SIZE\n",
    "\n",
    "input_img = Input(shape=(SIZE, SIZE, 1)) # normalized, 128 x 128\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(input_img) #nb_filter, nb_row, nb_col\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = ELU(alpha=1.0)(x)\n",
    "x = MaxPooling2D((4, 4))(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding='same',kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = ELU(alpha=1.0)(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "# x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "# x = BatchNormalization(axis=1)(x)\n",
    "# x = ELU(alpha=1.0)(x)\n",
    "# x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# print K.int_shape(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = ELU(alpha=1.0)(x)\n",
    "x = MaxPooling2D((2, 4))(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = ELU(alpha=1.0)(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(NB_CLASS)(x)\n",
    "y = Activation(\"softmax\")(x)\n",
    "\n",
    "model = Model(input_img, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128, 128, 32)      512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " elu (ELU)                   (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 64)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " elu_1 (ELU)                 (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 32)        18464     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16, 16, 32)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " elu_2 (ELU)                 (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 4, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 4, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 4, 32)          32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " elu_3 (ELU)                 (None, 8, 4, 32)          0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 2, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 2313      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 9)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49577 (193.66 KB)\n",
      "Trainable params: 49209 (192.22 KB)\n",
      "Non-trainable params: 368 (1.44 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3.9737654320987654, 1: 3.5225718194254445, 2: 13.770053475935828, 3: 9.196428571428571, 4: 13.696808510638299, 5: 18.52517985611511, 6: 14.385474860335195, 7: 21.822033898305083, 8: 24.523809523809526}\n"
     ]
    }
   ],
   "source": [
    "class_weight = {}\n",
    "total = drum_genres.shape[0]\n",
    "for i in range(NB_CLASS):\n",
    "    nb = np.sum(np.argmax(drum_genres, axis=1) == i)\n",
    "    class_weight[i] = total / float(nb) \n",
    "print (class_weight)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2575 2317\n"
     ]
    }
   ],
   "source": [
    "nb_total = drum_melspecs.shape[0]\n",
    "nb_train = int(nb_total * 0.9)\n",
    "print (nb_total, nb_train)\n",
    "\n",
    "train_melspecs = drum_melspecs[:nb_train]\n",
    "train_genres = drum_genres[:nb_train]\n",
    "\n",
    "val_melspecs = drum_melspecs[nb_train:]\n",
    "val_genres = drum_genres[nb_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2317, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_melspecs.shape\n",
    "train_genres.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 31s 809ms/step - loss: 2.5584 - acc: 0.9163 - val_loss: 0.7081 - val_acc: 0.7829\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 30s 803ms/step - loss: 1.9076 - acc: 0.9383 - val_loss: 0.6741 - val_acc: 0.7946\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 30s 799ms/step - loss: 1.7331 - acc: 0.9486 - val_loss: 0.6551 - val_acc: 0.8023\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 30s 804ms/step - loss: 1.6308 - acc: 0.9534 - val_loss: 0.6390 - val_acc: 0.8101\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 30s 806ms/step - loss: 1.5727 - acc: 0.9499 - val_loss: 0.6633 - val_acc: 0.8062\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 30s 805ms/step - loss: 1.4877 - acc: 0.9525 - val_loss: 0.6879 - val_acc: 0.8023\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 30s 803ms/step - loss: 1.4776 - acc: 0.9486 - val_loss: 0.6549 - val_acc: 0.8062\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 30s 819ms/step - loss: 1.5017 - acc: 0.9534 - val_loss: 0.7342 - val_acc: 0.8023\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 30s 813ms/step - loss: 1.5001 - acc: 0.9486 - val_loss: 0.7496 - val_acc: 0.7868\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2494f11ab30>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(verbose=1, patience=5)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "model.fit(train_melspecs, train_genres, batch_size=64, \n",
    "          epochs=100, verbose=1, \n",
    "          shuffle=False,validation_data = (val_melspecs, val_genres), class_weight=class_weight, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smsha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model/drum_spec_model_128.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert the model .5 tensorflow.js format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflowjs_converter --input_format=keras \\\n",
    "        C:/Users/smsha/Desktop/BeatboxAi/model/drum_spec_model_128.h5 \\\n",
    "        C:/Users/smsha/Desktop/BeatboxAi/model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
